runtime:
  seed: &seed 131
  deepspeed: True
  gradient_checkpointing: True
  gradient_accumulation_steps: &gas 1
  bf16: &bf16 True
  fp16: &fp16 False

deepspeed:
  enabled: True
  config:
    zero_optimization:
      stage: 2
      allgather_partitions: true
      allgather_bucket_size: 1.0e+8
      overlap_comm: true
      reduce_scatter: true
      reduce_bucket_size: 1.0e+8
      contiguous_gradients: true
    bf16:
      enabled: *bf16
    fp16:
      enabled: *fp16
      loss_scale: 0
      loss_scale_window: 100
      initial_scale_power: 16
      hysteresis: 2
      min_loss_scale: 1.0e-10
    steps_per_print: 2000
    gradient_clipping: 1.0
    wall_clock_breakdown: False
    zero_allow_untested_optimizer: true
    train_micro_batch_size_per_gpu: "auto"
    train_batch_size: "auto"
    gradient_accumulation_steps: *gas

tokenizer:
  type: QWenTokenizer_VL
  kwargs:
    tokenizer_name_or_path: &file_path 
    use_auth_token: False

tokenization: &tokenization
  type: sense_tokenization
  kwargs:
    with_tokenizer: True
    max_seq_length: &train_seq_length 2048
    parser_type: QWen_Vl
    parser_kwargs:
       prompt_template:
         eosys: "<|im_end|>\n"
         system_prompt: "You are a helpful assistant."
         eoh: "<|im_end|>\n"
         qustion_prompt: "<|im_start|>user\n"
         answer_prompt: "<|im_start|>assistant\n"

data:
  data_types: [train]
  train:
    dataset:
      type: base_nlp_json
      kwargs:
        json_file: pathtoyourjson
        transformer: [*tokenization]
        json_type: line
    batch_collector:
      type: batch_align
      kwargs:
        alignment: 1
        max_seq_length: *train_seq_length
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
        batch_size: 2
    data_loader:
      type: base
      kwargs:
        num_workers: 0
        pin_memory: True
        seed: *seed

trainer:
  train_iters: &train_iters 2000
  optimizer:
    type: AdamW
    kwargs:
      lr: 2.e-5
      weight_decay: 0
      betas: [0.9, 0.95]
      eps: 1.e-8
  lr_scheduler:
    type: hf_cosine
    kwargs:
      warmup_steps: 200
      training_steps: *train_iters

saver:
  enabled: False
  save_interval: 500
  save_path: checkpoints/qwen_vl
  save_mode: deepspeed
  save_optim: True
  save_rng_state: True


loader:
  enabled: False
  load_path: checkpoints/qwen_vl/checkpoint-500
  load_mode: deepspeed
  load_optim: True
  load_rng_state: True


hooks:
  - type: hf_train_val_logger
    kwargs:
      log_interval: 1
      tensorboard: False
  - type: dynamic_checkpoint
    kwargs:
        enable: False
        debug_freq: 10
        strategy:
          type: predefine
          kwargs:
            size_map:
              512: 0 
              1024: 16
              2048: 16

model:
  type: QWenForVL
  kwargs:
    model_name_or_path: *file_path
    torch_dtype: bfloat16
    trust_remote_code: True

infer_tokenization: 
  type: sense_tokenization
  kwargs:
    max_seq_length: *train_seq_length 
    parser_type: base
    parser_kwargs:
      prompt_type: qwen

infer_cfg:
  model_type: multimodal
  eval_task: ceval
  question_file: pathtoyourjson
  result_file: results.jsonl  # evaluation results file path
  generation_cfg:  # inference config
    temperature: 0.2
    top_k: 40
    top_p: 0.9
    do_sample: True
    num_beams: 1
    repetition_penalty: 1.3
    max_new_tokens: 512

